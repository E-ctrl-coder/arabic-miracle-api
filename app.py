from flask import Flask, request, jsonify
from flask_cors import CORS
import os
from openai import OpenAI
import re

app = Flask(__name__)
CORS(app)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Load Quran once at startup
with open("quraan.txt", "r", encoding="utf-8") as f:
    quraan_lines = [line.strip() for line in f if line.strip()]

def highlight_root(word, root_letters):
    highlighted = ""
    for char in word:
        if char in root_letters:
            highlighted += f"<span class='root'>{char}</span>"
        else:
            highlighted += char
    return highlighted

def find_quran_references(root_letters):
    matches = []
    count = 0
    root_set = set(root_letters)

    for verse in quraan_lines:
        if root_set & set(verse):  # basic filter
            root_hits = [c for c in verse if c in root_set]
            if len(root_hits) >= len(root_set):  # basic root match
                count += 1
                highlighted = highlight_root(verse, root_set)
                matches.append(highlighted)
                if len(matches) >= 3:
                    break

    return count, matches

@app.route("/analyze", methods=["POST"])
def analyze():
    data = request.get_json()
    word = data.get("word", "").strip()

    if not word:
        return jsonify({"error": "No word provided."}), 400

    try:
        prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„Ù„ØºÙˆÙŠØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„ØµØ±Ù Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ.

Ø­Ù„Ù„ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: "{word}"

ğŸ”¹ Ø£Ø¹Ø¯ ÙÙ‚Ø·:
1. Ø§Ù„Ø¬Ø°Ø± Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„Ù„ÙƒÙ„Ù…Ø©ØŒ Ù…Ø«Ø§Ù„: Ùƒ-Øª-Ø¨
2. Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù„Ù„Ø¬Ø°Ø±
3. Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù„Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
4. Ø§Ù„ÙˆØ²Ù† Ø§Ù„ØµØ±ÙÙŠ (Ø§Ù„Ù…ÙŠØ²Ø§Ù†) ÙˆÙ†ÙˆØ¹Ù‡

âœ… Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„ Ø¨Ø¯Ù‚Ø©:
Ø¬Ø°Ø± Ø§Ù„ÙƒÙ„Ù…Ø©: ...
ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¬Ø°Ø±: ...
Ù…Ø¹Ù†Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø©: ...
Ø§Ù„ÙˆØ²Ù† Ø§Ù„ØµØ±ÙÙŠ: ... (Ø§Ù„Ù†ÙˆØ¹: ...)

âŒ Ù„Ø§ ØªØ°ÙƒØ± Ø§Ù„Ø¢ÙŠØ§Øª Ø£Ùˆ Ø¹Ø¯Ø¯ Ù…Ø±Ø§Øª Ø§Ù„Ø¸Ù‡ÙˆØ±ØŒ Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø°Ù„Ùƒ Ø¨Ù†ÙØ³ÙŠ.
"""

        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        reply = response.choices[0].message.content.strip()

        # Extract results using regex
        root_match = re.search(r"Ø¬Ø°Ø± Ø§Ù„ÙƒÙ„Ù…Ø©:\s*([Ø£-ÙŠ\-]+)", reply)
        root_arabic = root_match.group(1).replace("-", "") if root_match else ""

        meaning_root = re.search(r"ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¬Ø°Ø±:\s*(.+)", reply)
        meaning_word = re.search(r"Ù…Ø¹Ù†Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø©:\s*(.+)", reply)
        scale_info = re.search(r"Ø§Ù„ÙˆØ²Ù† Ø§Ù„ØµØ±ÙÙŠ:\s*(.+?)\(Ø§Ù„Ù†ÙˆØ¹:\s*(.+?)\)", reply)

        # Lookup Quran references from local file
        count, verses = find_quran_references(root_arabic)

        return jsonify({
            "word": word,
            "root": root_arabic,
            "translation_root": meaning_root.group(1) if meaning_root else "",
            "translation_word": meaning_word.group(1) if meaning_word else "",
            "scale": scale_info.group(1).strip() if scale_info else "",
            "scale_type": scale_info.group(2).strip() if scale_info else "",
            "quran_count": count,
            "quran_verses": verses
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=10000)
